
# üß† SRAG (Simple RAG Library)

**SRAG** es una librer√≠a de Python modular, as√≠ncrona y fuertemente tipada dise√±ada para construir aplicaciones de **Retrieval Augmented Generation (RAG)** de manera escalable y mantenible.

A diferencia de los scripts monol√≠ticos, SRAG desacopla la l√≥gica en componentes intercambiables (Loaders, Chunkers, Embedders, VectorStores, LLMs), permitiendo crear pipelines complejos con facilidad.

## ‚ú® Caracter√≠sticas Principales

  * **‚ö° 100% As√≠ncrono:** Construido sobre `asyncio` para operaciones I/O no bloqueantes (ideal para APIs y alta concurrencia).
  * **üß© Dise√±o Modular:** Basado en interfaces abstractas (`ABC`). Cambia de `Ollama` a `OpenAI` o de `ChromaDB` a `Pinecone` sin romper tu l√≥gica de negocio.
  * **üõ°Ô∏è Type-Safe:** Uso extensivo de **Pydantic** para validaci√≥n de datos y **Type Hints** para una experiencia de desarrollo robusta.
  * **üìÑ LlamaParse Integration:** Soporte nativo para parsing avanzado de documentos (PDF, tablas) a Markdown.

## üì¶ Estructura del Proyecto

```text
src/srag/
‚îú‚îÄ‚îÄ core/           # Contratos e Interfaces (BaseLLM, BaseLoader...)
‚îú‚îÄ‚îÄ components/     # Implementaciones Concretas
‚îÇ   ‚îú‚îÄ‚îÄ loaders/    # LlamaParseLoader, etc.
‚îÇ   ‚îú‚îÄ‚îÄ chunkers/   # FixedLengthChunker, etc.
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/ # OllamaEmbeddings, etc.
‚îÇ   ‚îú‚îÄ‚îÄ vectorstores/ # ChromaVectorStore, etc.
‚îÇ   ‚îî‚îÄ‚îÄ llms/       # OllamaLLM, etc.
‚îî‚îÄ‚îÄ pipeline/       # (Pr√≥ximamente) Orquestaci√≥n de Ingesta
```

## üöÄ Inicio R√°pido

### Prerrequisitos

1.  **Python 3.10+**
2.  **Ollama** ejecut√°ndose localmente (para Embeddings y LLM).
3.  **LlamaCloud API Key** (si usas el loader de PDFs).

### Instalaci√≥n

Si usas `uv` (recomendado) o `pip`:

```bash
# Instalar dependencias
pip install ollama chromadb llama-parse pydantic python-dotenv pymupdf
```

Crea un archivo `.env` en la ra√≠z:

```env
LLAMA_CLOUD_API_KEY=llx-tu-api-key-aqui
```

### Ejemplo de Uso (End-to-End)

Este ejemplo muestra c√≥mo cargar un PDF, dividirlo, vectorizarlo y chatear con √©l.

```python
import asyncio
from srag.components.loaders import LlamaParseLoader
from srag.components.chunkers import FixedLengthChunker
from srag.components.embeddings import OllamaEmbeddings
from srag.components.vectorstores import ChromaVectorStore
from srag.components.llms import OllamaLLM

async def main():
    # 1. Configuraci√≥n de Componentes
    loader = LlamaParseLoader(file_paths=["documento.pdf"], save_output=False)
    chunker = FixedLengthChunker(chunk_size=500, overlap=50)
    embedder = OllamaEmbeddings(model="nomic-embed-text")
    vectorstore = ChromaVectorStore(collection_name="demo_rag")
    llm = OllamaLLM(model_name="llama3.2")

    # 2. Ingesta (Load -> Split -> Embed -> Store)
    print("üì• Cargando y procesando...")
    docs = await loader.load()
    chunks = chunker.split(docs)
    
    vectors = await embedder.embed_documents([c.content for c in chunks])
    for chunk, vector in zip(chunks, vectors):
        chunk.embedding = vector
        
    await vectorstore.add(chunks)
    print(f"‚úÖ Indexados {len(chunks)} fragmentos.")

    # 3. Chat (Retrieve -> Generate)
    query = "¬øCu√°les son los puntos clave del documento?"
    print(f"\nPregunta: {query}")
    
    # Retrieval
    query_vec = await embedder.embed_query(query)
    results = await vectorstore.search(query_vec, k=3)
    context = "\n".join([c.content for c in results])
    
    # Generation (Streaming)
    prompt = f"Contexto: {context}\n\nPregunta: {query}\nRespuesta:"
    print("Respuesta: ", end="", flush=True)
    async for token in llm.stream(prompt):
        print(token, end="", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

## üõ†Ô∏è Desarrollo y Testing

El proyecto utiliza `pytest` para las pruebas unitarias y de integraci√≥n.

```bash
# Ejecutar todos los tests
uv run pytest

# Ejecutar tests de un componente espec√≠fico
uv run pytest tests/components/loaders/
```

## üó∫Ô∏è Roadmap

  * [x]  Definici√≥n de interfaces core (`core`) y tipos de datos (`types`).
  * [x]  Implementaci√≥n de Componentes Base (Ollama, Chroma, LlamaParse).
  * [x]  Tests Unitarios as√≠ncronos.
  * [ ]  **Pipeline de Ingesta:** Orquestador autom√°tico ETL.
  * [ ]  **Estrategias RAG:** Implementaci√≥n de patrones como *Simple RAG*, *Hybrid Search* y *Contextual RAG*.
